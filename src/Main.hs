--
-- Copyright ¬© 2015, Patrick M. Niedzielski.
-- This file is part of fowlie-mga
--
-- fowlie-mga is free software: you can redistribute it and/or modify
-- it under the terms of the GNU General Public License as published
-- by the Free Software Foundation, either version 3 of the License,
-- or (at your option) any later version.
--
-- fowlie-mga is distributed in the hope that it will be useful, but
-- WITHOUT ANY WARRANTY; without even the implied warranty of
-- MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
-- General Public License for more details.
--
-- You should have received a copy of the GNU General Public License
-- along with fowlie-mga.  If not, see <http://www.gnu.org/licenses/>.
--

{-# LANGUAGE UnicodeSyntax #-}
{-# LANGUAGE MultiWayIf    #-}

module Main( main ) where

import System.Environment
import Data.Maybe
import Data.Matrix
import Data.Char
import Data.List
import Prelude.Unicode
import Control.Applicative
import Control.Monad.Unicode


--------------------------------------------------------------------------------
--                                                       0. TABLE OF CONTENTS --
--------------------------------------------------------------------------------


{-

This program is divided into the following sections:

0. TABLE OF CONTENTS  This section
1. PROGRAM STRUCTURE  The application main function
2. UTILITIES          Generic utilities used throughout the program
3. TOKENIZATION       Tokenization functionality
4. FEATURES           Selectional and Licensing feature types
5. LEXICON            Lexical items, with associated features
6. GRAMMAR            A lexicon and a set of start symbols
7. PARSING            CKY parser for MGs
8. RECOGNITION        Recognizer for MGs
9. USER-FACING        Helpful functions for the user to use

-}


--------------------------------------------------------------------------------
--                                                       1. PROGRAM STRUCTURE --
--------------------------------------------------------------------------------


-- | 'main' is the entry point of the program.  It reads each of its
-- command line arguments, parses each according to the grammar, and
-- prints the results to standard out.  If there are no command line
-- arguments, then each line of standard in is used instead.
main ‚à∑ IO ()
main = getInputs ‚â´= putStr ‚àò unlines ‚àò fmap (show ‚àò parse)
  where
    -- Return command line arguments if there are any, and stdin lines
    -- otherwise.
    getInputs = do
      args  ‚Üê getArgs
      stdin ‚Üê getLines
      return $ selectNotNull args stdin
    -- Return the first argument unless it is the empty list, in which
    -- case return the second argument.
    selectNotNull [] xs = xs
    selectNotNull xs _  = xs
    -- Return a lazy list of lines from standard in.
    getLines = getContents ‚â´= return ‚àò lines


--------------------------------------------------------------------------------
--                                                               2. UTILITIES --
--------------------------------------------------------------------------------


-- | '‚Ñï' is the natural numbers.  For efficiency, this is just an alias
-- for ‚Ñ§, and its only purpose in life is to make it a little clearer
-- that we don't want negative numbers.
type ‚Ñï = Int

-- | 'Œµ' is the empty string.
Œµ ‚à∑ String
Œµ = ""

-- | 'nullToNothing' maps an empty list to Nothing and a nonempty list
-- to Just that list.
nullToNothing ‚à∑ [Œ±] ‚Üí Maybe [Œ±]
nullToNothing [] = Nothing
nullToNothing x  = Just x

-- | 'stabilize' returns the cycle of a transformation 't' that has a
-- single value cycle when applied to 'initial'.  Precondition: 't'^ùìÉ
-- applied to 'initial' describes an orbit over a subset of Œ± with a
-- cycle that contains a single value.
stablize ‚à∑ Eq Œ± ‚áí (Œ± ‚Üí Œ±) ‚Üí Œ± ‚Üí Œ±
stablize f initial
  | initial' ‚â° initial = initial
  | otherwise          = stablize f initial'
  where initial' = f initial


--------------------------------------------------------------------------------
--                                                            3. TOKENIZATION --
--------------------------------------------------------------------------------


-- | 'Token' is the orthographic representation of a lexical item.  It
-- is normalized to all lowercase characters, and has no internal
-- whitespace.
type Token = String

-- | 'tokenize' takes an input string and returns a list of its
-- tokens.
tokenize ‚à∑ String ‚Üí [Token]
tokenize = words ‚àò fmap toLower  -- normalize to lowercase and then
                                 -- split on space


--------------------------------------------------------------------------------
--                                                                4. FEATURES --
--------------------------------------------------------------------------------


-- | A 'Selectional' feature is one that drives Merge.  A categorial
-- feature ùêπ and a selector feature =ùêπ can Merge to form a larger
-- tree.
type Selectional = String

-- | A 'Licensing' feature is one that drives Move.  A licensor
-- feature +ùêπ and a licensee feature -ùêπ are checked by a Move to
-- reorder the constituents in the tree.
type Licensing   = String

-- | A 'Feature' is either a selectional feature or a licensing
-- feature.
data Feature = Category Selectional
             | Selector Selectional
             | Licensor Licensing
             | Licensee Licensing
             deriving( Eq )

instance Show Feature where
  show (Category f) = f
  show (Selector f) = "=" ‚ß∫ f
  show (Licensor f) = "+" ‚ß∫ f
  show (Licensee f) = "-" ‚ß∫ f


--------------------------------------------------------------------------------
--                                                                 5. LEXICON --
--------------------------------------------------------------------------------


-- | A 'LexicalItem' is a pairing of an orthographic representation
-- that appears in the surface string and a list of features that must
-- be checked in a valid parse.
data LexicalItem = LexicalItem( Token, [Feature] )
                 deriving( Eq )

instance Show LexicalItem where
  show (LexicalItem( token, f )) = token ‚ß∫ " ‚à∑ " ‚ß∫ featureString
    where featureString = unwords $ fmap show f

-- | 'featuresOf' returns the list of features associated with a
-- lexical item.
featuresOf ‚à∑ LexicalItem ‚Üí [Feature]
featuresOf (LexicalItem( _, f )) = f

-- | 'tokenOf' returns the surface form associated with a lexical
-- item.
tokenOf ‚à∑ LexicalItem ‚Üí Token
tokenOf (LexicalItem( token, _ )) = token

-- | A 'Lexicon' is simply a list of lexical entries, with no
-- duplcates.
type Lexicon = [LexicalItem]


--------------------------------------------------------------------------------
--                                                                 6. GRAMMAR --
--------------------------------------------------------------------------------


-- | A 'Grammar' is just a lexicon and a set of start symbols in MG.
type Grammar = ([Selectional], Lexicon)

-- | 'lexicon' returns a grammar's lexicon
lexicon ‚à∑ Grammar ‚Üí Lexicon
lexicon (_, l) = l

-- | 'startSymbols' returns a grammar's set of start symbols.
startSymbols ‚à∑ Grammar ‚Üí [Selectional]
startSymbols (s, _) = s

-- | 'findInLexicon' returns a list of all lexical items with the
-- given surface form.  Because we allow homophony in our lexicon,
-- this has to return a list.
findInLexicon ‚à∑ Token ‚Üí Grammar ‚Üí [LexicalItem]
findInLexicon t = filter (\x ‚Üí tokenOf x ‚â° t) ‚àò lexicon

-- | 'emptyItems' returns a list of all lexical items with no surface
-- form (i.e., such that the surface form is Œµ).
emptyItems ‚à∑ Grammar ‚Üí [LexicalItem]
emptyItems = findInLexicon Œµ

-- | 'grammar' is a test grammar.
grammar ‚à∑ Grammar
grammar =
  (["C"],
   [ LexicalItem( "fox",     [Category "N"]                                )
   , LexicalItem( "the",     [Selector "N", Category "D"]                  )
   , LexicalItem( "marie",   [Category "D", Licensee "case"]               )
   , LexicalItem( "pierre",  [Category "D"]                                )
   , LexicalItem( "praises", [Selector "D", Selector "D", Category "V"]    )
   , LexicalItem( Œµ,         [Selector "V", Licensor "case", Category "T"] )
   , LexicalItem( Œµ,         [Selector "T", Category "C"]                  )
   ])


--------------------------------------------------------------------------------
--                                                                 7. PARSING --
--------------------------------------------------------------------------------

-- | Each chain has a 'Type' that is either 'Lexical' or 'Derived'.
-- 'Lexical' chains consist only of lexical items, whereas 'Derived'
-- chains are the result of a merge or move operation.
data Type = Lexical | Derived
          deriving( Eq, Ord, Show )

-- | A 'Chain' is a contiguous forest (represented as a start and end
-- pair in the chart), a type, and a set of features.
data Chain = Chain( (‚Ñï, ‚Ñï), Type, [Feature] )
           deriving( Eq )

instance Show Chain where
  show (Chain( pos, t, fs) ) =
    show pos ‚ß∫ showNoCoords (Chain (pos, t, fs))

showNoCoords ‚à∑ Chain ‚Üí String
showNoCoords (Chain( _, Lexical, fs )) = foldl (‚ß∫) "ùìÅ " $ fmap show fs
showNoCoords (Chain( _, Derived, fs )) = foldl (‚ß∫) Œµ    $ fmap show fs

-- | An 'Expression' is a non-empty list of chains.  An invalid
-- expression (formed by calling 'merge' or 'move' on arguments not
-- within its definition space) is represented by an empty list.
type Expression = [Chain]

data ChartEntry = ChartEntry Expression
                deriving( Eq )

instance Show ChartEntry where
  show (ChartEntry( [] ))     = ""
  show (ChartEntry( x : xs )) = showNoCoords x ‚ß∫ show' xs
    where show' [] = Œµ
          show' xs = " " ‚ß∫ (unwords $ fmap show xs)

-- | 'merge' Takes a left-hand chart entry and a right-hand chart
-- entry and attempts to merge them according to the three MG merge
-- functions.  If the merge fails, we return an empty list.
merge ‚à∑ Expression ‚Üí Expression ‚Üí Expression

-- merge1: merge lexical entry with something else
merge ( Chain( (s, _),   Lexical,   Selector f  : Œ≥  ) : [] )
      ( Chain( (_, e),         _,   Category f' : [] ) : Œ±s )
  | f ‚â° f'   = newExpr
  | otherwise = []
  where newChain = Chain( (s, e), Derived, Œ≥ )
        newExpr  = [newChain] ‚ß∫ Œ±s

-- merge2: merge something with derived entry
merge ( Chain( (s, _),         _,   Category f  : [] ) : Œ≤s )
      ( Chain( (_, e),   Derived,   Selector f' : Œ≥  ) : Œ±s )
  | f ‚â° f'   = newExpr
  | otherwise = []
  where newChain = Chain( (s, e), Derived, Œ≥ )
        newExpr = [newChain] ‚ß∫ Œ±s ‚ß∫ Œ≤s

-- merge3: merge two things with further requirements
merge ( Chain( pos ,          t ,   Category f  : Œ≥  ) : Œ≤s )
      ( Chain( pos',          t',   Selector f' : Œ¥  ) : Œ±s )
  | f ‚â° f'   = newExpr
  | otherwise = []
  where newChain  = Chain( pos', t', Œ¥ )
        newChain' = Chain( pos , t , Œ≥ )
        newExpr   = [newChain] ‚ß∫ Œ±s ‚ß∫ [newChain'] ‚ß∫ Œ≤s
merge ( Chain( pos',          t',   Selector f' : Œ¥  ) : Œ±s )
      ( Chain( pos ,          t ,   Category f  : Œ≥  ) : Œ≤s )
  | f ‚â° f'   = newExpr
  | otherwise = []
  where newChain  = Chain( pos', t', Œ¥ )
        newChain' = Chain( pos , t , Œ≥ )
        newExpr   = [newChain] ‚ß∫ Œ±s ‚ß∫ [newChain'] ‚ß∫ Œ≤s

-- otherwise, don't merge
merge _ _ = []

partialParseTokens ‚à∑ [Token] ‚Üí Maybe [ChartEntry]
partialParseTokens input =
  nullToNothing $ ChartEntry <$> parseResults
    where parseResults = cky g input start end
          start        = 0
          end          = length input
          g            = grammar

parseTokens ‚à∑ [Token] ‚Üí Maybe [ChartEntry]
parseTokens input =
     partialParseTokens input
  ‚â´= nullToNothing ‚àò filter (\(ChartEntry x) ‚Üí isValidParse x)
    where isValidParse = isStartSymbol g
          g            = grammar

isStartSymbol ‚à∑ Grammar ‚Üí Expression ‚Üí Bool
isStartSymbol g [Chain (_, _, [Category f])] = f ‚àà startSymbols g
isStartSymbol _ _                            = False

cky ‚à∑ Grammar ‚Üí [Token] ‚Üí ‚Ñï ‚Üí ‚Ñï ‚Üí [Expression]
cky g input start end
  | invalidCell     = []
  | emptyCatCell    = emptyItemEntries
  | lexicalCell     = lexicalItemEntries
  | otherwise       = stablize (nub ‚àò mergeWithEmpties) constituents
  where
    -- What type of cell is (start, end)?
    invalidCell  = end < start      -- Unused cell
    emptyCatCell = start ‚â° end      -- Œµ entries
    lexicalCell  = end - start ‚â° 1  -- Lexical entries
    -- Convert lexical items to chart entries
    lexicalToChart l    = [Chain ((start, end), Lexical, featuresOf l)]
    -- All empty items.
    emptyItemEntries   = lexicalToChart <$> emptyItems g
    -- All lexical items that are homophonous with token.  This allows
    -- us to capture lexical ambiguity.
    lexicalItemEntries = fmap lexicalToChart lexicalItems
    lexicalItems       = findInLexicon token g
    token              = input !! start
    -- Finds all possible constituents.
    constituents       =
      do
        midpoint ‚Üê [(start + 1) .. (end - 1)]
        lhs      ‚Üê cky g input start midpoint
        rhs      ‚Üê cky g input midpoint end
        return $ merge lhs rhs
    mergeWithEmpties items =
      items ‚ß∫ do
        lhs      ‚Üê cky g input start start
        rhs      ‚Üê items
        return $ merge lhs rhs

fullChart ‚à∑ Grammar -> [Token] ‚Üí Matrix [ChartEntry]
fullChart g input = fmap (fmap ChartEntry) $ fromLists $ do
  x ‚Üê [0..end]
  return $
    do
      y ‚Üê [0..end]
      return $ filter (not ‚àò null) $ cky g input x y
        where end = length input


--------------------------------------------------------------------------------
--                                                             8. RECOGNITION --
--------------------------------------------------------------------------------


-- | 'recognize' takes a list of tokens and returns whether the list
-- of tokens can be generated by the language.
recognizeTokens ‚à∑ [Token] ‚Üí Bool
recognizeTokens = isJust ‚àò parseTokens


--------------------------------------------------------------------------------
--                                                            9. USER-FACING  --
--------------------------------------------------------------------------------


parse        = parseTokens        ‚àò tokenize
partialParse = partialParseTokens ‚àò tokenize
recognize    = recognizeTokens    ‚àò tokenize
